{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-29T07:31:48.837803Z",
     "iopub.status.busy": "2020-11-29T07:31:48.836822Z",
     "iopub.status.idle": "2020-11-29T07:31:48.842840Z",
     "shell.execute_reply": "2020-11-29T07:31:48.842311Z"
    },
    "papermill": {
     "duration": 0.023436,
     "end_time": "2020-11-29T07:31:48.842951",
     "exception": false,
     "start_time": "2020-11-29T07:31:48.819515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-29T07:31:48.868585Z",
     "iopub.status.busy": "2020-11-29T07:31:48.867945Z",
     "iopub.status.idle": "2020-11-29T07:31:49.724095Z",
     "shell.execute_reply": "2020-11-29T07:31:49.722993Z"
    },
    "papermill": {
     "duration": 0.869969,
     "end_time": "2020-11-29T07:31:49.724221",
     "exception": false,
     "start_time": "2020-11-29T07:31:48.854252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010522,
     "end_time": "2020-11-29T07:31:49.745912",
     "exception": false,
     "start_time": "2020-11-29T07:31:49.735390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:31:49.776897Z",
     "iopub.status.busy": "2020-11-29T07:31:49.776145Z",
     "iopub.status.idle": "2020-11-29T07:31:56.122694Z",
     "shell.execute_reply": "2020-11-29T07:31:56.123293Z"
    },
    "papermill": {
     "duration": 6.366621,
     "end_time": "2020-11-29T07:31:56.123450",
     "exception": false,
     "start_time": "2020-11-29T07:31:49.756829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 23814\n",
      "Number of features:876\n",
      "Number of target outputs: 207\n",
      "Number of test examples: 3982\n",
      "The submission file should be of dimension:  3982 x 207\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "\n",
    "test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n",
    "\n",
    "print('Number of training examples: {}'.format(train_features.shape[0]))\n",
    "print('Number of features:{}'.format(train_features.shape[1]))\n",
    "print('Number of target outputs: {}'.format(train_targets.shape[1]))\n",
    "print('Number of test examples: {}'.format(test_features.shape[0]))\n",
    "\n",
    "print('The submission file should be of dimension: ', test_features.shape[0],'x', train_targets.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011322,
     "end_time": "2020-11-29T07:31:56.146755",
     "exception": false,
     "start_time": "2020-11-29T07:31:56.135433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Extract the column names from the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:31:56.183877Z",
     "iopub.status.busy": "2020-11-29T07:31:56.181800Z",
     "iopub.status.idle": "2020-11-29T07:31:56.186815Z",
     "shell.execute_reply": "2020-11-29T07:31:56.185921Z"
    },
    "papermill": {
     "duration": 0.028875,
     "end_time": "2020-11-29T07:31:56.187027",
     "exception": false,
     "start_time": "2020-11-29T07:31:56.158152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genetic expression features: 772\n",
      "Number of cell viability features: 100\n",
      "Other features: 4\n"
     ]
    }
   ],
   "source": [
    "def feature_columns(data):\n",
    "    g_feats = []\n",
    "    c_feats = []\n",
    "    others = []\n",
    "    for feature in data.columns:\n",
    "        if feature.find('c-')!=-1:\n",
    "            c_feats.append(feature)\n",
    "        elif feature.find('g-')!=-1:\n",
    "            g_feats.append(feature)\n",
    "        else:\n",
    "            others.append(feature)\n",
    "    return c_feats, g_feats, others\n",
    "\n",
    "c_feats, g_feats, others = feature_columns(train_features)\n",
    "\n",
    "print('Number of genetic expression features: {}'.format(len(g_feats)))\n",
    "print('Number of cell viability features: {}'.format(len(c_feats)))\n",
    "print('Other features: {}'.format(len(others)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011584,
     "end_time": "2020-11-29T07:31:56.211634",
     "exception": false,
     "start_time": "2020-11-29T07:31:56.200050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare dataset for model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01239,
     "end_time": "2020-11-29T07:31:56.236236",
     "exception": false,
     "start_time": "2020-11-29T07:31:56.223846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Import packages for feature engineering and model generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:31:56.267442Z",
     "iopub.status.busy": "2020-11-29T07:31:56.266610Z",
     "iopub.status.idle": "2020-11-29T07:32:01.064326Z",
     "shell.execute_reply": "2020-11-29T07:32:01.063220Z"
    },
    "papermill": {
     "duration": 4.816379,
     "end_time": "2020-11-29T07:32:01.064482",
     "exception": false,
     "start_time": "2020-11-29T07:31:56.248103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping \n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012204,
     "end_time": "2020-11-29T07:32:01.089270",
     "exception": false,
     "start_time": "2020-11-29T07:32:01.077066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Augment features using PCA on training data**\n",
    "\n",
    "Include citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:32:01.137164Z",
     "iopub.status.busy": "2020-11-29T07:32:01.136476Z",
     "iopub.status.idle": "2020-11-29T07:36:27.998355Z",
     "shell.execute_reply": "2020-11-29T07:36:27.999254Z"
    },
    "papermill": {
     "duration": 266.898018,
     "end_time": "2020-11-29T07:36:27.999514",
     "exception": false,
     "start_time": "2020-11-29T07:32:01.101496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "(23814, 503)\n",
      "(23814, 206)\n"
     ]
    }
   ],
   "source": [
    "#check if all ids match in training features and training targets\n",
    "def check_ids(features, targets):\n",
    "    for i in range(train_features.shape[0]):\n",
    "        if train_features['sig_id'][i]!= train_targets['sig_id'][i]:\n",
    "            print('Mismatch detected!')\n",
    "    print('Done!')\n",
    "    \n",
    "check_ids(train_features, train_targets)\n",
    "    \n",
    "def preprocess_categorical(data):\n",
    "    data.loc[:,'cp_type'] = data.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    data.loc[:,'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1':0, 'D2':1})\n",
    "    return data\n",
    "\n",
    "def feature_augment(aug_data, feature_set, n_comp):\n",
    "    data_pca = PCA(n_components = n_comp, random_state = 7).fit_transform(aug_data[feature_set])\n",
    "    train_pca_feat = data_pca[:train_features.shape[0]]\n",
    "    test_pca_feat = data_pca[-test_features.shape[0]:]\n",
    "    return train_pca_feat, test_pca_feat\n",
    "\n",
    "X = train_features.drop(labels = 'sig_id', axis = 1)\n",
    "X = preprocess_categorical(X)\n",
    "\n",
    "X_test = test_features.drop(labels = 'sig_id', axis = 1)\n",
    "X_test = preprocess_categorical(X_test)\n",
    "\n",
    "#begin data augmentation\n",
    "# aug_data_g = pd.concat([pd.DataFrame(train_features[g_feats]), \n",
    "#                        pd.DataFrame(test_features[g_feats])])\n",
    "# aug_data_c = pd.concat([pd.DataFrame(train_features[c_feats]), \n",
    "#                        pd.DataFrame(test_features[c_feats])])\n",
    "\n",
    "# g_num, c_num = 500, 50\n",
    "\n",
    "# train_g_add, test_g_add = feature_augment(aug_data_g, g_feats, g_num)\n",
    "# train_c_add, test_c_add = feature_augment(aug_data_c, c_feats, c_num)\n",
    "\n",
    "# train_g_add = pd.DataFrame(train_g_add, columns=[f'pca_G-{i}' for i in range(g_num)])\n",
    "# test_g_add = pd.DataFrame(test_g_add, columns=[f'pca_G-{i}' for i in range(g_num)])\n",
    "\n",
    "# train_c_add = pd.DataFrame(train_c_add, columns=[f'pca_C-{i}' for i in range(c_num)])\n",
    "# test_c_add = pd.DataFrame(test_c_add, columns=[f'pca_C-{i}' for i in range(c_num)])\n",
    "\n",
    "# X = pd.concat((X, train_g_add, train_c_add), axis=1)\n",
    "# X_test = pd.concat((X_test, test_g_add, test_c_add), axis=1)\n",
    "\n",
    "#Remove features with low variance\n",
    "var_thresh = VarianceThreshold(0.95)\n",
    "data = X.append(X_test)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 3:])\n",
    "\n",
    "#Perform Quantile Transformation to adjust outliers\n",
    "# QUA = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "# data_transformed = QUA.fit_transform(data_transformed)\n",
    "data_transformed = MinMaxScaler().fit_transform(data_transformed)\n",
    "\n",
    "#Perform ICA to reduce dimensionality of data \n",
    "ica = FastICA(n_components=500,max_iter=500)\n",
    "data_transformed_ica=ica.fit_transform(data_transformed)\n",
    "\n",
    "train_transform = data_transformed_ica[ : train_features.shape[0]]\n",
    "test_transform = data_transformed_ica[-test_features.shape[0] : ]\n",
    "\n",
    "X_train_features = pd.DataFrame(X[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n",
    "                              columns=['cp_type','cp_time','cp_dose'])\n",
    "X = pd.concat([X_train_features, pd.DataFrame(train_transform)], axis=1)\n",
    "\n",
    "\n",
    "X_test_features = pd.DataFrame(X_test[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n",
    "                             columns=['cp_type','cp_time','cp_dose'])\n",
    "X_test = pd.concat([X_test_features, pd.DataFrame(test_transform)], axis=1)\n",
    "\n",
    "#end augmentation\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "y = train_targets.drop(labels = 'sig_id', axis = 1)\n",
    "\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012126,
     "end_time": "2020-11-29T07:36:28.025075",
     "exception": false,
     "start_time": "2020-11-29T07:36:28.012949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build Deep Neural Network Model that learns patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:36:28.061695Z",
     "iopub.status.busy": "2020-11-29T07:36:28.060932Z",
     "iopub.status.idle": "2020-11-29T07:36:28.063353Z",
     "shell.execute_reply": "2020-11-29T07:36:28.064001Z"
    },
    "papermill": {
     "duration": 0.0266,
     "end_time": "2020-11-29T07:36:28.064117",
     "exception": false,
     "start_time": "2020-11-29T07:36:28.037517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "INPUT_DIM = X.shape[1]\n",
    "OUTPUT_DIM = y.shape[1]\n",
    "HIDDEN_1 = [1024, 512, 256]\n",
    "HIDDEN_2 = [512, 512, 256]\n",
    "HIDDEN_3 = [1024, 512, 512]\n",
    "\n",
    "def create_model(hidden_layers, input_dim = INPUT_DIM, output_dim = OUTPUT_DIM):\n",
    "    inp = layers.Input(shape = (input_dim, ))\n",
    "    x = inp\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    for units in hidden_layers:\n",
    "        x = tfa.layers.WeightNormalization(layers.Dense(units))(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "    \n",
    "#     x = layers.Dropout(0.1)(x)\n",
    "    outp = tfa.layers.WeightNormalization(layers.Dense(output_dim, activation = 'sigmoid'))(x)\n",
    "    \n",
    "    model = models.Model(inputs = inp, outputs = outp, name = 'multioutput_model')\n",
    "    \n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:36:28.110182Z",
     "iopub.status.busy": "2020-11-29T07:36:28.097691Z",
     "iopub.status.idle": "2020-11-29T07:43:41.800911Z",
     "shell.execute_reply": "2020-11-29T07:43:41.799622Z"
    },
    "papermill": {
     "duration": 433.723875,
     "end_time": "2020-11-29T07:43:41.801077",
     "exception": false,
     "start_time": "2020-11-29T07:36:28.077202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1............................................\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 1\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.4740 - val_loss: 0.1115\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0606 - val_loss: 0.0328\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0242\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0232 - val_loss: 0.0215\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0199\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0186\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0178\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0157\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 2\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.1352 - val_loss: 0.0230\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0219\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0118 - val_loss: 0.0160\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0161\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 3\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.1322 - val_loss: 0.0225\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0169\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0164\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0158\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0155\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0158\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0113 - val_loss: 0.0158\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 4\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 13ms/step - loss: 0.1335 - val_loss: 0.0227\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0218\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0158\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0159\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 5\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.1350 - val_loss: 0.0226\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0209\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0191\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 2s 14ms/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Training Model 2............................................\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 1\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.4794 - val_loss: 0.1254\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0610 - val_loss: 0.0346\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0291 - val_loss: 0.0255\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0233 - val_loss: 0.0218\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0200\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0176 - val_loss: 0.0170\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0164\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0155\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0156\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0156\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0156\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 2\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 14ms/step - loss: 0.1354 - val_loss: 0.0227\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0198 - val_loss: 0.0211\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0168\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 3\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.1339 - val_loss: 0.0224\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0217\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0192\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0158\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0154\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0156\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 4\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.1324 - val_loss: 0.0230\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0218\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0211\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0157\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0159\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 5\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.1328 - val_loss: 0.0225\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0215\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Training Model 3............................................\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 1\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.4201 - val_loss: 0.0764\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0433 - val_loss: 0.0282\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0226\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0222\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.0156\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0158\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 2\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.1182 - val_loss: 0.0225\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0218\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0209\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0185\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0157\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0160\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 3\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.1162 - val_loss: 0.0219\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0208\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0114 - val_loss: 0.0158\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0110 - val_loss: 0.0158\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 4\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.1165 - val_loss: 0.0220\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0161\n",
      "-----------------------------------------------------------\n",
      "Training on Fold: 5\n",
      "-----------------------------------------------------------\n",
      "Epoch 1/25\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.1144 - val_loss: 0.0219\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0215\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 2s 12ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0157\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0156\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0156\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0117 - val_loss: 0.0158\n",
      "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
      "0  id_0004d9e33                     0.001967                0.002431   \n",
      "1  id_001897cda                     0.000315                0.000414   \n",
      "2  id_002429b5b                     0.000062                0.000087   \n",
      "3  id_00276f245                     0.000612                0.000437   \n",
      "4  id_0027f1083                     0.000752                0.001949   \n",
      "\n",
      "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
      "0        0.001213                        0.008664   \n",
      "1        0.001700                        0.002510   \n",
      "2        0.000143                        0.000682   \n",
      "3        0.001330                        0.011340   \n",
      "4        0.001568                        0.007967   \n",
      "\n",
      "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
      "0                           0.011770                        0.004740   \n",
      "1                           0.001778                        0.001949   \n",
      "2                           0.001749                        0.000273   \n",
      "3                           0.009356                        0.002638   \n",
      "4                           0.019819                        0.002944   \n",
      "\n",
      "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
      "0                    0.002262                       0.005447   \n",
      "1                    0.003659                       0.011070   \n",
      "2                    0.000160                       0.000388   \n",
      "3                    0.002218                       0.001411   \n",
      "4                    0.007661                       0.000587   \n",
      "\n",
      "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
      "0                    0.000483  ...                               0.000567   \n",
      "1                    0.002875  ...                               0.000812   \n",
      "2                    0.000023  ...                               0.000038   \n",
      "3                    0.000114  ...                               0.000301   \n",
      "4                    0.000551  ...                               0.000280   \n",
      "\n",
      "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
      "0      0.001513         0.002195           0.000347   \n",
      "1      0.000762         0.012235           0.000256   \n",
      "2      0.000075         0.000221           0.000120   \n",
      "3      0.000325         0.001344           0.007321   \n",
      "4      0.000213         0.002326           0.003105   \n",
      "\n",
      "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
      "0                   0.000531                               0.000808   \n",
      "1                   0.003699                               0.000222   \n",
      "2                   0.000303                               0.000053   \n",
      "3                   0.007024                               0.000322   \n",
      "4                   0.000541                               0.000671   \n",
      "\n",
      "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
      "0         0.001471   0.002843                    0.004113       0.001792  \n",
      "1         0.000838   0.000549                    0.000881       0.003502  \n",
      "2         0.000919   0.000213                    0.000233       0.000108  \n",
      "3         0.001624   0.001954                    0.000233       0.000885  \n",
      "4         0.000978   0.001089                    0.000209       0.001226  \n",
      "\n",
      "[5 rows x 207 columns]\n",
      "Converting to csv file.....................\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 5\n",
    "\n",
    "def train_model_k_fold(X, y, hidden_layers, epochs = EPOCHS, batch_size = BATCH_SIZE):\n",
    "    kf = KFold(n_splits = N_FOLDS, random_state = 1, shuffle = True)\n",
    "    history, index = {}, 0\n",
    "    \n",
    "    model_predict = sample_sub.copy()\n",
    "    model_predict.loc[:, y.columns] = 0\n",
    "    \n",
    "#     opt = optimizers.Adam(learning_rate = 0.001)\n",
    "    opt = tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5, clipvalue=700)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 10)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    for train, val in kf.split(X,y):\n",
    "        \n",
    "        model = create_model(hidden_layers)\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = opt)\n",
    "        \n",
    "        print('-----------------------------------------------------------')\n",
    "        print('Training on Fold: {}'.format(index+1))\n",
    "        print('-----------------------------------------------------------')\n",
    "        \n",
    "        X_train, X_val = X.values[train], X.values[val]\n",
    "        y_train, y_val = y.values[train], y.values[val]\n",
    "        history[index] = model.fit(X_train, y_train, validation_data = (X_val, y_val), \n",
    "                                epochs = epochs, batch_size = batch_size,\n",
    "                                callbacks = [early_stop])\n",
    "        prediction = model.predict(X_test.values[:])\n",
    "        model_predict.loc[:, y.columns] += prediction/N_FOLDS\n",
    "        index += 1\n",
    "    return model, model_predict\n",
    "\n",
    "submission_predict = sample_sub.copy()\n",
    "submission_predict.loc[:, y.columns] = 0\n",
    "\n",
    "print('Training Model 1............................................')\n",
    "model1, model1_predict = train_model_k_fold(X, y, hidden_layers = HIDDEN_1)\n",
    "\n",
    "print('Training Model 2............................................')\n",
    "model2, model2_predict = train_model_k_fold(X, y, hidden_layers = HIDDEN_2)\n",
    "\n",
    "print('Training Model 3............................................')\n",
    "model3, model3_predict = train_model_k_fold(X, y, hidden_layers = HIDDEN_3)\n",
    "\n",
    "weight = [0.25, 0.5, 0.25]\n",
    "model_predict = [model1_predict, model2_predict, model3_predict]\n",
    "\n",
    "for i in range(3):\n",
    "    curr_model = model_predict[i]\n",
    "    submission_predict.loc[:, y.columns] += weight[i]*curr_model.loc[:, y.columns]\n",
    "# submission_predict.loc[:, y.columns] +=model2_predict.loc[:, y.columns]\n",
    "print(submission_predict[:5])\n",
    "\n",
    "print('Converting to csv file.....................')\n",
    "submission_predict.to_csv('submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:43:46.542229Z",
     "iopub.status.busy": "2020-11-29T07:43:46.541234Z",
     "iopub.status.idle": "2020-11-29T07:43:46.543334Z",
     "shell.execute_reply": "2020-11-29T07:43:46.543832Z"
    },
    "papermill": {
     "duration": 2.392716,
     "end_time": "2020-11-29T07:43:46.544008",
     "exception": false,
     "start_time": "2020-11-29T07:43:44.151292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_model(X, y, hidden_layers, epochs = EPOCHS, batch_size = BATCH_SIZE):\n",
    "    \n",
    "#     opt = tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5, clipvalue=700)\n",
    "#     reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 10)\n",
    "#     early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    \n",
    "#     print('-----------------------------------------------------------')\n",
    "#     print('Performing hold-out validation')\n",
    "#     print('-----------------------------------------------------------')\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.25, \n",
    "#                                               random_state = True, shuffle = True)\n",
    "#     model = create_model(hidden_layers)\n",
    "#     model.compile(loss = 'binary_crossentropy', optimizer = opt)\n",
    "#     history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = epochs, \n",
    "#                    batch_size = batch_size, callbacks = [reduce_lr, early_stop])\n",
    "#     plot_train_result(history)\n",
    "#     return model\n",
    "\n",
    "# def plot_train_result(history):\n",
    "#     plt.figure()\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.legend(['Training Loss', 'Validation Loss'])\n",
    "#     plt.show()\n",
    "\n",
    "# model1 = train_model(X, y, hidden_layers = HIDDEN_1)\n",
    "# model2 = train_model(X, y, hidden_layers = HIDDEN_2)\n",
    "# model3 = train_model(X, y, hidden_layers = HIDDEN_3)\n",
    "\n",
    "# submission_predict = sample_sub.copy()\n",
    "# submission_predict.loc[:, y.columns] = 0\n",
    "\n",
    "# weight = [0.15, 0.7, 0.15]\n",
    "# model = [model1, model2, model3]\n",
    "\n",
    "# for i in range(3):\n",
    "#     submission_predict.loc[:, y.columns] += weight[i]*model[i].predict(X_test.values[:])\n",
    "\n",
    "# print(submission_predict[:5])\n",
    "\n",
    "# print('Converting to csv file.....................')\n",
    "# submission_predict.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 726.467038,
   "end_time": "2020-11-29T07:43:51.116230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-29T07:31:44.649192",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
